% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[10pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage[english]{babel}

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{wrapfig}

\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% TILTLE AND AUTHOR

\title{
	Predictive Text
}


\author{Y3839090}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 
\makeatletter

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{1pt} % customise the layout...
\lhead{\@title}\chead{}\rhead{\@author}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

% biblatex for citations
\usepackage{csquotes}
\usepackage[
backend=biber,
style=numeric,
sorting=ynt
]{biblatex}
\addbibresource{references.bib}
\usepackage{url}

\graphicspath{{Images/}}

%%% END Article customizations

%%% The "real" document content comes below...


\begin{document}

	\begin{titlepage}
		\centering
		\includegraphics[width=0.5\textwidth]{UoY_logo}\par\vspace{1cm}
		{\scshape\LARGE Department of Electronics \par}
		\vspace{1cm}
		{\scshape\Large Data Structures and Algorithms Assessment \par}
		\vspace{2cm}
		{\huge\bfseries Predictive Text\par}

		% maybe an image here
	
		\vfill
		{\Large\itshape \@author \par}
		\vspace{2cm}
		{\large \today\par}
	\end{titlepage}
	
	\tableofcontents
	\newpage
	
	\section{What is a predictive Text system and how do they work}
		A predictive text system's (also known as  auto-complete or word completion) role is to take a partial word and return a list of suggestions. They use some form of dictionary of known words to offer these suggestions.
		\subsection{How users interact with the program}
			Users interact with predictive text systems via some kind of text input device. Most users interact with some kind of predictive text system on a daily basis on either their PC or mobile device. The UI for both desktop and mobile devices follow the same basic pattern. The user begins by entering text normally via a keyboard or touch screen and once there are a sufficient number of letters for the system to make a reasonable guess (often two letters), the system presents the user with a list of predicted words. The user is then able to press a key to select which of the suggestions they want to use or continue typing and ignore the systems suggestions. The word they were typing replaces the partial word so that the user can move on the the next word.
		\subsection{Behaviour of predictive text systems}
			Predictive text system often return result that fall into a few broad categories.
			\begin{description}
				\item [The input.] One of the options in a predictive text system is always to keep the partial word that you already have. This is often achieved by returning the input as one of the items in the suggestion list. This behaviour can also happen if the partial word is actually a valid word from the predictive text systems dictionary.
				\item [A word prefixed by the partial word.] The most common results from predictive text systems are words that are prefixed by the partial word the user has entered (e.g. ``hel" may return [``hel\textit{p}",``hel\textit{l}",``hel\textit{lo}"]). 
				\item [A word that shares a prefix with the partial word.] (e.g. ``applez" may return [``apple",``apples",``app"]) 
			\end{description}
			
			More sophisticated system may also use frequency analysis techniques, lexicographical distance algorithms and consider context to make smarter suggestions. These are out side of the scope of this project ( Our dictionary doesn't contain any frequency data or phrase data).

	\section{Requirements}
		Now that a predictive text systems behaviour has been defined, a set of success criteria can be derived.
		\begin{enumerate}
			\item The system must use ANSI C .
			\item The system must compile with minGW (gcc)
			\item The system must compile and execute correctly on the university lab machines in PT108.
			\item The system must load a word dictionary from file. \textit{(provided file words.txt)}
			
			\item The system must be capable of adding the loaded words into a data structure to store them whilst the program is running
			\item The system must store these words in a space efficient data structure.
			\item The system must be able to access these words in a time efficient manner.
			
			\item The system must be able to check to see if a partial word is contained in that data structure.
			\item The system must be able to check to see if a partial word is a valid word from the dictionary
			\item The system must be able to make suggestions of words that are prefixed by a partial word.
			\item The system must be able to make suggestions of words that share a common prefix with a partial word.
			
			\item The system must let the user enter a string of text.
			\item The system must present the users with suggestions as they are typing (preferred) or the user should be able to trigger a suggestion mode where they will be presented with a set of suggestions.
			\item The system should let the user select the one of these suggestions.
			\item The system should replace the partial word with the selected word.
			
			\item The system could be extended to deal with punctuation.
			\item The system could be extended to deal with Capitalisation.
			
		\end{enumerate}
	\section{Data Structures}
		A predictive text program needs a to be able to access a set of common words.
		 Storing and accessing these words efficiently is one of the challenges in creating a fast predictive text engine.
		  I decided to use a trie\cite{book:ADS:trie} structure.
		  
		\subsection{Trie}
			\subsubsection{What is a trie}
			
				\begin{wrapfigure}{r}{0.33\textwidth} %this figure will be at the right
    				\centering
    				\includegraphics[width=0.33\textwidth]{Trie_example}
    				\caption{A trie for keys "A","to", "tea", "ted", "ten", "i", "in", and "inn"\cite{fig:Trie_example}.}
    				\label{fig:Trie_example}
				\end{wrapfigure}
				
				The trie is a tree-like data structure often used for storing strings. Each node in the trie represents a single letter in a string. Each node in a trie has a fixed number of child nodes like a binary search tree. Unlike the binary search tree the trie does not have two child nodes, it has one for each letter of the alphabet. This allows the trie nodes to not store their value because their position determines it. A node's children share a common prefix, that prefix is the value of there parent node.

                There are many features of tries that make them a good choice for a predictive text system. One of them is that values can be look up by their prefixes. Predictive text systems use a partial word (a prefix) to search for possible full words. So it's important that prefix look-ups are fast and efficient. [TODO:: ADD MORE STUFF HERE]
				
			\subsubsection{Time complexity of a trie}
				The search time for a value in a trie is \begin{math}O(len(string))\end{math}, where \begin{math}len(string)\end{math} is the length of the word to look up\cite{book:ADS:complexity}. This gives the trie a \begin{math} O(1) \end{math} search time. Meaning that searches in a trie do not depend on the number of items in the trie. A predictive text function relies upon looks. Every time a user presses a key the system will preform at least one look up and so it is vital that these searches be fast. 
				
				The time complexity of deletion in a trie is also linear. Deletions time complexity is 
				\begin{math}O(\vert A \vert len(string))\end{math}, where \begin{math}len(string)\end{math} is the length of the word to look up and \begin{math}\vert A \vert \end{math} is the size of the alphabet\cite{book:ADS:complexity}. In the use case as a Predictive text engine deletions will be very rare or non-existent. A simple implementation of predictive text may not allow the user to delete words form the dictionary at all. 
				
				The time complexity of insertion in a trie is the same as for deletions. Insertion time complexity is \begin{math}O(\vert A \vert len(string))\end{math}, where \begin{math}len(string)\end{math} is the length of the word to look up and \begin{math}\vert A \vert \end{math} is the size of the alphabet\cite{book:ADS:complexity}. When used in a predictive text engine most of the insertion into the trie will be made when loading the dictionary from file. 
			\subsubsection{Space complexity of a trie}
			    The space complexity of a trie is \begin{math} O(\vert A \vert \Sigma_i len(w_i))\end{math} where there are strings \begin{math} w_0 \end{math} to \begin{math} w_n \end{math} and \begin{math}\vert A \vert \end{math} is the size of the alphabet \cite{book:ADS:complexity}. This is saying that the space complexity of a trie is equal to the size of the alphabet by the total length of all the strings. Expressed in therms of \begin{math} n \end{math} this becomes \begin{math} O(\vert A \vert * n * l )\end{math} where \begin{math}\vert A \vert \end{math} is the size of the alphabet and \begin{math} l \end{math} is the average length of the words. In this form it is easy to see that the space required to store is governed by a  \begin{math} O(n) \end{math} relationship ship.
			    
            \subsubsection{Space vs Time}
                The tire data structure sacrifices a good space complexity for time complexity that doesn't depend on the number of strings that it is storing. 
                
		\subsection{Alternative Data structures}
			\subsubsection{Binary Trees vs Tries}
			
			\subsubsection{Hash map vs Tries}
			\subsubsection{List vs Tries}
	\section{Testing}
		\subsection{Complixity}
			\subsubsection{Time Complexity of Tries}
				

				
		\subsection{Unit Testing}
		\subsection{User interactions}
		
	\newpage
	\printbibliography
	\newpage
	
\end{document}
